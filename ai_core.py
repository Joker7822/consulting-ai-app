import re
import math
import random
from typing import List, Dict, Any

import pandas as pd

# =========================
# ãƒ†ãƒ³ãƒ—ãƒ¬/è¾æ›¸
# =========================
INDUSTRY_WEIGHTS = {
    "å°å£²/EC":      {"awareness":1.0, "consideration":1.1, "conversion":1.2, "retention":1.0, "referral":0.9},
    "é£²é£Ÿ":         {"awareness":1.1, "consideration":1.0, "conversion":1.2, "retention":1.1, "referral":1.0},
    "ç¾å®¹/ã‚µãƒ­ãƒ³":  {"awareness":1.0, "consideration":1.1, "conversion":1.2, "retention":1.1, "referral":1.0},
    "æ•™è‚²/ã‚¹ã‚¯ãƒ¼ãƒ«":{"awareness":1.0, "consideration":1.2, "conversion":1.0, "retention":1.1, "referral":0.9},
    "B2Bã‚µãƒ¼ãƒ“ã‚¹":  {"awareness":0.9, "consideration":1.2, "conversion":1.0, "retention":1.2, "referral":1.0},
    "ã‚¯ãƒªãƒ‹ãƒƒã‚¯/åŒ»ç™‚":{"awareness":0.9, "consideration":1.1, "conversion":1.2, "retention":1.1, "referral":0.9},
    "ä¸å‹•ç”£":       {"awareness":0.9, "consideration":1.2, "conversion":1.0, "retention":1.0, "referral":0.8},
    "ãã®ä»–":       {"awareness":1.0, "consideration":1.0, "conversion":1.0, "retention":1.0, "referral":1.0},
}

CHANNEL_TIPS = {
    "SNS": ["ä¿å­˜ç‡KPI/é€£è¼‰ã‚«ãƒ«ãƒ¼ã‚»ãƒ«", "ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«â†’LPå°ç·šã‚’æ˜ç¤º", "UGCã®åé›†ã¨äºŒæ¬¡æ´»ç”¨"],
    "æ¤œç´¢": ["æ‚©ã¿KWã§è¨˜äº‹åŒ–", "æ¯”è¼ƒ/ãƒ©ãƒ³ã‚­ãƒ³ã‚°å‹ã§CVå°ç·š", "å†…éƒ¨ãƒªãƒ³ã‚¯æœ€é©åŒ–"],
    "åºƒå‘Š": ["å¦å®šKW/é™¤å¤–é¢æ£šå¸ã—", "LPãƒ’ãƒ¼ãƒ­ãƒ¼ã‚³ãƒ”ãƒ¼AB", "è¨ˆæ¸¬ã®äºŒé‡/æœªè¨ˆæ¸¬ã‚’ç‚¹æ¤œ"],
    "ãƒ¡ãƒ¼ãƒ«/LINE":["ã‚ªãƒ³ãƒœ3é€šè¨­è¨ˆ", "ä»¶åã¯ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆå…ˆè¡Œ", "ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé…ä¿¡"],
}

GLOSSARY = {
    "CTR": "åºƒå‘Šã‚„ãƒªãƒ³ã‚¯ã®è¡¨ç¤ºå›æ•°ã«å¯¾ã™ã‚‹ã‚¯ãƒªãƒƒã‚¯ç‡ã€‚Click Through Rateã€‚",
    "CVR": "ã‚¯ãƒªãƒƒã‚¯ã‹ã‚‰æˆç´„ã«è‡³ã‚‹å‰²åˆã€‚Conversion Rateã€‚",
}
GLOSSARY.update({
    "CPA": "1ä»¶ã®æˆç´„ã«ã‹ã‹ã£ãŸåºƒå‘Šè²»ã€‚Cost Per Acquisitionã€‚",
    "CPC": "1ã‚¯ãƒªãƒƒã‚¯ã‚ãŸã‚Šã®åºƒå‘Šè²»ã€‚Cost Per Clickã€‚",
    "CPM": "1000å›è¡¨ç¤ºã‚ãŸã‚Šã®åºƒå‘Šè²»ã€‚Cost Per Milleã€‚",
    "LTV": "é¡§å®¢ãŒç”Ÿæ¶¯ã‚’é€šã˜ã¦ç”Ÿã¿å‡ºã™ç²—åˆ©ã®åˆè¨ˆã€‚é¡§å®¢ç”Ÿæ¶¯ä¾¡å€¤ã€‚",
    "AARRR": "èªçŸ¥â†’æ¤œè¨â†’æˆç´„â†’ç¶™ç¶šâ†’ç´¹ä»‹ã®æˆé•·ãƒ•ãƒ¬ãƒ¼ãƒ ã€‚",
})

def explain_terms(text: str, enabled: bool = True) -> str:
    """ç”¨èªé›†ã«è¼‰ã£ã¦ã„ã‚‹å°‚é–€ç”¨èªã‚’ã‚„ã•ã—ã„æ—¥æœ¬èªã§æ‹¬å¼§æ›¸ãè£œè¶³ã™ã‚‹ã€‚
    enabled=False ã®ã¨ãã¯åŸæ–‡ã‚’è¿”ã™ã€‚
    """
    if not enabled or not text:
        return text
    # é•·ã„èªã‹ã‚‰ç½®æ›ã—ã¦èª¤çˆ†ã‚’æ¸›ã‚‰ã™
    for term in sorted(GLOSSARY.keys(), key=len, reverse=True):
        meaning = GLOSSARY[term]
        # ã™ã§ã«æ‹¬å¼§ãŒä»˜ã„ã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        pattern = rf"\b{re.escape(term)}(?!ï¼ˆ)"
        text = re.sub(pattern, f"{term}ï¼ˆ{meaning}ï¼‰", text)
    return text

def humanize(text: str, tone: str) -> str:
    if tone == "ã‚„ã•ã—ã‚": return "ğŸ˜Š " + text
    if tone == "å…ƒæ°—ã«èƒŒä¸­æŠ¼ã—": return "ğŸ”¥ " + text + " ã„ã‘ã¾ã™ï¼"
    return text

def smartify_goal(text: str) -> str:
    if not text: return "ä»Šé€±ï¼šä¸»è¦CV 10 ä»¶ï¼ˆCTR1.5%ãƒ»CVR3%ãƒ»ç›´å¸°ç‡<60%ï¼‰"
    m = re.search(r"(\d+)", text)
    num = m.group(1) if m else "10"
    return f"ä»Šé€±ï¼šä¸»è¦CV {num} ä»¶ï¼ˆæ¸¬å®šï¼šGA/åºƒå‘Šã€åŸºæº–ï¼šCTR1.5%ãƒ»CVR3%ãƒ»ç›´å¸°ç‡<60%ï¼‰"

def funnel_diagnosis(inputs: Dict[str, Any]) -> Dict[str, Any]:
    w = INDUSTRY_WEIGHTS.get(inputs.get("industry","ãã®ä»–"), INDUSTRY_WEIGHTS["ãã®ä»–"])
    def s(k, d=50):
        try: return max(0, min(100, int(inputs.get(k, d))))
        except: return d
    scores = {
        "Awareness(èªçŸ¥)": round(s("score_awareness",50)*w["awareness"],1),
        "Consideration(æ¤œè¨)": round(s("score_consideration",50)*w["consideration"],1),
        "Conversion(æˆç´„)": round(s("score_conversion",50)*w["conversion"],1),
        "Retention(ç¶™ç¶š)": round(s("score_retention",50)*w["retention"],1),
        "Referral(ç´¹ä»‹)": round(s("score_referral",50)*w["referral"],1),
    }
    return {"scores": scores, "bottleneck": min(scores, key=scores.get)}

def kpi_backsolve(inputs: Dict[str, Any]) -> pd.DataFrame:
    text = (inputs.get("goal") or "") + " " + (inputs.get("objective") or "")
    m = re.search(r"(\d+)", text)
    target_cv = int(m.group(1)) if m else 10
    ctr = 0.015; cvr = 0.03; lead_rate = 0.30
    clicks = math.ceil(target_cv / cvr)
    imps   = math.ceil(clicks / ctr)
    leads  = math.ceil(clicks * lead_rate)
    return pd.DataFrame([
        {"æŒ‡æ¨™":"å¿…è¦CVæ•°","ç›®æ¨™å€¤":target_cv,"ãƒ¡ãƒ¢":"goalã‹ã‚‰æŠ½å‡ºï¼ˆæœªæŒ‡å®šã¯10ï¼‰"},
        {"æŒ‡æ¨™":"å¿…è¦ã‚¯ãƒªãƒƒã‚¯æ•°","ç›®æ¨™å€¤":clicks,"ãƒ¡ãƒ¢":f"CVR {int(cvr*100)}%æƒ³å®š"},
        {"æŒ‡æ¨™":"å¿…è¦ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³","ç›®æ¨™å€¤":imps,"ãƒ¡ãƒ¢":f"CTR {int(ctr*100)}%æƒ³å®š"},
        {"æŒ‡æ¨™":"å¿…è¦ãƒªãƒ¼ãƒ‰/é–‹å§‹æ•°","ç›®æ¨™å€¤":leads,"ãƒ¡ãƒ¢":f"é–‹å§‹ç‡ {int(lead_rate*100)}%æƒ³å®š"},
    ])

def budget_allocation(inputs: Dict[str, Any]) -> pd.DataFrame:
    budget = max(0, int(inputs.get("budget", 0)))
    channels = inputs.get("channels", ["SNS","æ¤œç´¢","åºƒå‘Š","ãƒ¡ãƒ¼ãƒ«/LINE"])[:4]
    goal = (inputs.get("goal") or "") + (inputs.get("objective") or "")
    weights = {}
    for ch in channels:
        if ch == "åºƒå‘Š": w = 1.5 if any(k in goal for k in ["äºˆç´„","CV","ç”³è¾¼","å£²ä¸Š"]) else 1.1
        elif ch == "æ¤œç´¢": w = 1.4 if any(k in goal for k in ["è³‡æ–™","æ¯”è¼ƒ","æ¤œè¨","æ¤œç´¢"]) else 1.1
        elif ch == "SNS": w = 1.2 if any(k in goal for k in ["èªçŸ¥","ãƒ•ã‚©ãƒ­","ä¿å­˜","æ‹¡æ•£"]) else 1.0
        elif ch == "ãƒ¡ãƒ¼ãƒ«/LINE": w = 1.3 if any(k in goal for k in ["å†æ¥åº—","ãƒªãƒ”ãƒ¼ãƒˆ","ç¶™ç¶š","LTV"]) else 1.0
        else: w = 1.0
        weights[ch] = w
    total_w = sum(weights.values()) or 1
    rows = []
    for ch in channels:
        amount = round(budget * (weights[ch]/total_w))
        tips = " / ".join(random.sample(CHANNEL_TIPS.get(ch.split("(")[0], ["åŸºæœ¬ã‚’å¾¹åº•"]), k=min(2, len(CHANNEL_TIPS.get(ch.split("(")[0], ["åŸºæœ¬ã‚’å¾¹åº•"])))))
        rows.append({"ãƒãƒ£ãƒãƒ«": ch, "æ¨å¥¨é…åˆ†(å††/é€±)": amount, "æˆ¦è¡“ãƒ’ãƒ³ãƒˆ": tips})
    return pd.DataFrame(rows)

def three_horizons_actions(inputs: Dict[str, Any], tone: str, with_reason: bool = False) -> Dict[str, List[Any]]:
    product = inputs.get("product","ã‚µãƒ¼ãƒ“ã‚¹")
    target = inputs.get("target","ã‚ãªãŸ")
    bottleneck = funnel_diagnosis(inputs)["bottleneck"]
    # ã‚¿ã‚¹ã‚¯ã¨ç†ç”±ã®ãƒšã‚¢
    today_pairs = [
        ("å„ªå…ˆåº¦ï¼šãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã¯ **{bottleneck}**ã€‚ã“ã“ã«åŠ¹ãã‚¿ã‚¹ã‚¯ã‹ã‚‰ç€æ‰‹ã€‚".format(bottleneck=bottleneck),
         "é™ã‚‰ã‚ŒãŸæ™‚é–“/äºˆç®—ã§æœ€å¤§ã®åŠ¹æœã‚’å‡ºã™ãŸã‚ã€æœ€ã‚‚å¼±ã„ç®‡æ‰€ã‚’å…ˆã«å¼·åŒ–ã—ã¾ã™ï¼ˆãƒœãƒˆãƒ«ãƒãƒƒã‚¯æ€è€ƒï¼‰ã€‚"),
        ("LPãƒ’ãƒ¼ãƒ­ãƒ¼â€œèª°ã®/ä½•ã®æ‚©ã¿/ã©ã†è§£æ±ºâ€ã‚’1ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã§è¡¨ç¾",
         "è¨ªå•ç›´å¾Œã«ä¾¡å€¤ãŒä¼ã‚ã‚‹ã¨ç›´å¸°ç‡ãŒä¸‹ãŒã‚Šã€æˆç´„ç‡ï¼ˆCVRï¼‰ãŒä¸ŠãŒã‚Šã¾ã™ã€‚"),
        ("åºƒå‘Šï¼šå¦å®šKW/é™¤å¤–é¢ã‚’10ä»¶æ£šå¸ã—",
         "ç„¡é§„ãªè¡¨ç¤ºã‚’æ¸›ã‚‰ã—ã€ã‚¯ãƒªãƒƒã‚¯ç‡ï¼ˆCTRï¼‰ã¨è²»ç”¨å¯¾åŠ¹æœï¼ˆCPAï¼‰ã‚’æ”¹å–„ã—ã¾ã™ã€‚"),
        ("SNSï¼šä¿å­˜ç‡ã‚’ç‹™ã†â€œãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆæŠ•ç¨¿â€ã‚’1æœ¬",
         "â€œä¿å­˜â€ã¯å¾Œã§è¦‹è¿”ã•ã‚Œã‚„ã™ãã€å†è¨ªã‚„æ¤œè¨ã®æ·±ã¾ã‚Šã«ã¤ãªãŒã‚Šã¾ã™ã€‚"),
    ]
    week_pairs = [
        ("è¨ˆæ¸¬æ£šå¸ã—ï¼ˆUTM/CVï¼‰â†’ {product} ç”³è¾¼ã¾ã§å¯è¦–åŒ–".format(product=product),
         "ã©ã®çµŒè·¯ãŒæˆæœã«ã¤ãªãŒã£ãŸã‹ã‚’è¦‹ãˆã‚‹åŒ–ã—ã€æŠ•è³‡åˆ¤æ–­ã‚’æ”¹å–„ã—ã¾ã™ã€‚"),
        ("ABè¨ˆç”»ï¼šãƒ’ãƒ¼ãƒ­ãƒ¼è¦‹å‡ºã—ï¼ˆç—›ã¿ vs ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆï¼‰ã‚’7æ—¥",
         "æ„æ€æ±ºå®šã®è¦ã¯ç¬¬ä¸€å°è±¡ã€‚è¦‹å‡ºã—ã®æ¤œè¨¼ã§CVRãŒå¤§ããå¤‰ã‚ã‚Šã¾ã™ã€‚"),
        ("CRMï¼šã‚ªãƒ³ãƒœé…ä¿¡3é€šï¼ˆä¾¡å€¤â†’ä¸å®‰è§£æ¶ˆâ†’ç· åˆ‡ï¼‰",
         "åˆå›ä½“é¨“ã®è³ªã‚’ä¸Šã’ã€é›¢è„±ã‚’é˜²ãã€ç¶™ç¶š/LTVã‚’é«˜ã‚ã¾ã™ã€‚"),
    ]
    month_pairs = [
        ("æ¤œç´¢ï¼šæ‚©ã¿KWÃ—3ã®æ¯”è¼ƒ/HowToè¨˜äº‹â†’å†…éƒ¨ãƒªãƒ³ã‚¯ã§LPã¸",
         "â€œä»Šã™ãå®¢â€ä»¥å¤–ã«ã‚‚â€œæ¤œè¨å±¤â€ã‚’æ‹¾ã„ã€ä½ã‚³ã‚¹ãƒˆã§è³ªã®é«˜ã„æµå…¥ã‚’ä½œã‚Šã¾ã™ã€‚"),
        ("å‹ã¡æŠ•ç¨¿ã®é‡ç”£ä½“åˆ¶ï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬åŒ–/UGCè¨±è«¾ï¼‰",
         "å†ç¾æ€§ã‚’ä½œã£ã¦é‹ç”¨è² è·ã‚’ä¸‹ã’ã€å®‰å®šçš„ã«æˆæœã‚’ç©ã¿ä¸Šã’ã¾ã™ã€‚"),
        ("ç´¹ä»‹å°ç·šï¼š{target}ãŒé…ã‚Šã‚„ã™ã„ç´¹ä»‹ã‚«ãƒ¼ãƒ‰ã¨ç‰¹å…¸".format(target=target),
         "ä¿¡é ¼çµŒç”±ã®ç²å¾—ã¯CVRãŒé«˜ãã€åºƒå‘Šä¾å­˜ã‚’ä¸‹ã’ã‚‰ã‚Œã¾ã™ï¼ˆAARRRã®â€œReferralâ€ï¼‰ã€‚"),
    ]
    def render(lines):
        if with_reason:
            return [humanize(f"{t}ï½œç†ç”±ï¼š{r}", tone) for (t,r) in lines]
        else:
            return [humanize(t, tone) for (t,_) in lines]
    return {
        "ä»Šæ—¥ã‚„ã‚‹": render(today_pairs),
        "ä»Šé€±ã‚„ã‚‹": render(week_pairs),
        "ä»Šæœˆã‚„ã‚‹": render(month_pairs),
    }

def concrete_examples(inputs: Dict[str, Any], tone: str) -> Dict[str, str]:
    product = inputs.get("product","ã‚µãƒ¼ãƒ“ã‚¹")
    usp = inputs.get("strength","å¼·ã¿")
    target = inputs.get("target","ã‚ãªãŸ")
    sns = f"ã€ä¿å­˜ç‰ˆã€‘{target}ãŒã‚„ã‚ã‚‹ã¹ã3ã¤ã®ãƒ ãƒ€ â†’ {product}ã§â€œãƒ©ã‚¯ã«â€è§£æ±ºï½œ{usp}"
    ad = f"{product}ï½œã¾ãšã¯7æ—¥ãŠè©¦ã—ã€‚{usp}ã€‚ç”³è¾¼3åˆ†ã€‚ä»Šãªã‚‰ç‰¹å…¸ã‚ã‚Šã€‚"
    lp = f"{target}ã®â€œå›°ã£ãŸâ€ã‚’7æ—¥ã§è§£æ±ºã€‚{product} â€” {usp}ã€‚ã¾ãšã¯ç„¡æ–™ã§ä½“é¨“ã€‚"
    dm = f"ã¯ã˜ã‚ã¾ã—ã¦ï¼{product}ã¸ã®é–¢å¿ƒã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚ã„ã¾å›°ã£ã¦ã„ã‚‹ã“ã¨ã‚’30ç§’ã§æ•™ãˆã¦ãã ã•ã„ã€‚ä»Šæ—¥ã‹ã‚‰ä¸€æ­©é€²ã‚ã‚‹æ–¹æ³•ã‚’é€ã‚Šã¾ã™ğŸ™Œ"
    call = f"æœ¬æ—¥ã¯â€œå£ã‚’1ã¤ç‰¹å®šã—ã¦æ¬¡ã®1æ‰‹ã‚’æ±ºã‚ã‚‹â€ãŒã‚´ãƒ¼ãƒ«ã§ã™ã€‚è³ªå•3ã¤â†’çµè«–â†’æ¬¡ã®äºˆå®šã§5åˆ†ã§çµ‚ã‚ã‚Šã¾ã™ã€‚"
    sns_p = "â€œä¿å­˜ç‰ˆâ€ã¨ã„ã†èªã‚’å…¥ã‚Œã‚‹ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¾Œã§è¦‹è¿”ã—ãŸããªã‚Šã€å†è¨ªã¨æ¤œè¨ã®æ·±ã¾ã‚Šã«åŠ¹ãã¾ã™ã€‚"
    ad_p = "æœŸé™ã‚„ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆã‚’æ˜ç¤ºã™ã‚‹ã¨è¿·ã„ã‚’æ¸›ã‚‰ã—ã€ã‚¯ãƒªãƒƒã‚¯ç‡ï¼ˆCTRï¼‰ã¨æˆç´„ç‡ï¼ˆCVRï¼‰ã«åŠ¹ãã¾ã™ã€‚"
    lp_p = "1ç”»é¢ã§â€œèª°ã®/ä½•ã®æ‚©ã¿/ã©ã†è§£æ±ºâ€ã‚’ç¤ºã™ã¨ç›´å¸°ç‡ãŒä¸‹ãŒã‚Šã€CVRãŒä¸ŠãŒã‚Šã¾ã™ã€‚"
    dm_p = "åŒæ–¹å‘ã®è³ªå•ã‚’å…¥ã‚Œã‚‹ã¨è¿”ä¿¡ç‡ãŒä¸ŠãŒã‚Šã€é–¢ä¿‚æ§‹ç¯‰ã®ãã£ã‹ã‘ã«ãªã‚Šã¾ã™ã€‚"
    call_p = "ç›®çš„ã‚’å…ˆã«å…±æœ‰ã™ã‚‹ã¨ã€ä¼šè©±ãŒãƒ–ãƒ¬ãšã«çŸ­æ™‚é–“ã§æ„æ€æ±ºå®šã§ãã¾ã™ã€‚"
    return {
        "SNSæŠ•ç¨¿": humanize(sns, tone),
        "SNSãƒã‚¤ãƒ³ãƒˆ": humanize(sns_p, tone),
        "åºƒå‘Šæ–‡": humanize(ad, tone),
        "åºƒå‘Šãƒã‚¤ãƒ³ãƒˆ": humanize(ad_p, tone),
        "LPãƒ’ãƒ¼ãƒ­ãƒ¼": humanize(lp, tone),
        "LPãƒã‚¤ãƒ³ãƒˆ": humanize(lp_p, tone),
        "DMãƒ†ãƒ³ãƒ—ãƒ¬": humanize(dm, tone),
        "DMãƒã‚¤ãƒ³ãƒˆ": humanize(dm_p, tone),
        "é›»è©±ãƒˆãƒ¼ã‚¯": humanize(call, tone),
        "é›»è©±ãƒã‚¤ãƒ³ãƒˆ": humanize(call_p, tone),
    }

def build_utm(url: str, source="instagram", medium="social", campaign="launch", content="post") -> str:
    if not url: return ""
    join = "&" if "?" in url else "?"
    return f"{url}{join}utm_source={source}&utm_medium={medium}&utm_campaign={campaign}&utm_content={content}"
